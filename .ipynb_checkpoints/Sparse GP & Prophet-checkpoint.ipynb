{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "import experiment_config_gpflow as config\n",
    "import experiment_funcs_gpflow as ef\n",
    "from fbprophet import Prophet\n",
    "from analysis_gpflow import Analyst\n",
    "import scipy.stats as sps\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Periodicity is '1D', '1W', '1M', '1Q', '1Y' etc\n",
    "def prophet_fcast(train, test, periodicity):\n",
    "\n",
    "   u, std = train.mean(), train.std()\n",
    "\n",
    "   train_norm = (train - u)/std\n",
    "   test_norm = (test - u)/std\n",
    "\n",
    "   train_size = train_norm.shape[0]\n",
    "   test_size = test_norm.shape[0]\n",
    "   total_size = train_size + test_size\n",
    "\n",
    "   dates = pd.date_range(start='2000-01-01', periods=total_size, freq=periodicity)\n",
    "   dates_train = dates[:train_size]\n",
    "   dates_test = dates[train_size:total_size]\n",
    "\n",
    "   train_df = pd.DataFrame()\n",
    "   train_df['ds'] = dates_train\n",
    "   train_df['y'] = train_norm\n",
    "\n",
    "   test_df = pd.DataFrame()\n",
    "   test_df['ds'] = dates_test\n",
    "   test_df['y'] = test_norm\n",
    "\n",
    "   m_def = Prophet(interval_width=0.95)\n",
    "   m_def = m_def.fit(train_df)\n",
    "   forecast = m_def.predict(test_df)\n",
    "\n",
    "   return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SEE experiment_config_gpflow.py for the experiment configurations\n",
    "# I have added [:1] to the second and third loop so it runs only once (one file, one model)\n",
    "df_results = []\n",
    "for folder in config.DATA_FOLDERS:\n",
    "    \n",
    "    \n",
    "    location = Path(config.DATA_ROOT).joinpath(folder)\n",
    "    trainFiles = list(filter(lambda name: 'train' in name, os.listdir(location)))\n",
    "    \n",
    "    for file in trainFiles[:1]:\n",
    "        \n",
    "        # This is a lazy evaluator, it returns a function that will be called inside the training routine\n",
    "        # if you want access to it just set data = data() \n",
    "        data = ef.read_experiment_data(folder, location, file)()\n",
    "        idx = ef.get_idx(file)\n",
    "        \n",
    "        for kName in list(config.EXPERIMENTS.keys())[:1]:\n",
    "            \n",
    "            print(kName)\n",
    "            \n",
    "            # Experiment input\n",
    "            inputs = ef.ExperimentInput(kName, data, config.EXPERIMENTS[kName],\n",
    "                                        config.LIKELIHOOD_EXPERIMENT.get(kName, config.LIKELIHOOD_DEFAULT),\n",
    "                                        config.MODEL_EXPERIMENT.get(kName, config.MODEL_DEFAULT),\n",
    "                                        config.PRIORS_EXPERIMENT.get(kName, config.PRIOR_DEFAULT),\n",
    "                                        config.SCORE.get(kName, config.SCORE_DEFAULT),\n",
    "                                        config.INDUCING_EXPERIMENT.get(kName, config.INDUCING_DEFAULT),\n",
    "                                        config.N_RESTARTS.get(kName, config.N_RESTARTS_DEF))\n",
    "            \n",
    "            # Models because returns a list with one model per checkpoint (number of restarts)\n",
    "            # In the config file I set only the last one\n",
    "            # Models is a list of (reg, goodness, in_, failed) -> gpflow model, score, input, failed training\n",
    "            # Training parameters are inside model_gpflow.py\n",
    "            models = ef.train_model(inputs)\n",
    "            for m in models:\n",
    "                # Saves serialized results in the file and outputs dataframe with results\n",
    "                # This gets saved in the results folder\n",
    "                out_results = ef.save_model_results(m)\n",
    "                df_results.append(out_results)\n",
    "        \n",
    "        # Prophet\n",
    "        # Electricity dataset has daily observations\n",
    "        # data['ytrain'], data['ytest'] are already normalized\n",
    "        forecast = prophet_fcast(data['ytrain'], data['ytest'], '1D')\n",
    "        analyst = Analyst(None, data, 'prophet', 'waic', period=1)\n",
    "        stdFcast = (forecast[['yhat_upper']].values-forecast[['yhat']].values)/sps.norm.ppf(0.975)\n",
    "        out_prophet = analyst.measures_dict(forecast[['yhat']].values, stdFcast, data['ytest'], 'prophet')\n",
    "        out_prophet['folder'] = folder\n",
    "        out_prophet['idx'] = idx\n",
    "        df_results.append(pd.DataFrame([out_prophet]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(df_results).groupby('name').mean()[['crps', 'mae', 'rmse', 'smape']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
